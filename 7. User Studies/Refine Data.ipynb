{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the given dirty raw data and refine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bson\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is Pro, -1 is Anti\n",
    "def getLabeledData(csvFile, pklFile):\n",
    "    def combine(s):\n",
    "        return list(s)\n",
    "    \n",
    "    def stance(df):\n",
    "        grouped = df.groupby(['ID'])\n",
    "        result = grouped['Label'].agg(['sum', 'count'])\n",
    "        sums = grouped['Label'].sum()\n",
    "        result['Label'] = np.select(condlist=[sums>0, sums==0, sums<0], choicelist=[1, 0, -1], \n",
    "            default=np.nan)\n",
    "        result = result.drop(columns=['sum', 'count'])\n",
    "        \n",
    "        result['Texts'] = grouped['Statement'].agg([combine])\n",
    "        \n",
    "        return result\n",
    "\n",
    "    pred_data = pd.read_csv(csvFile) \n",
    "\n",
    "    pred_data['Label'] = pred_data['Label'].replace(['PRO'], 1)\n",
    "    pred_data['Label'] = pred_data['Label'].replace(['ANTI'], -1)\n",
    "    \n",
    "    #return pred_data\n",
    "    return stance(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We match the given data, from the big courpus to obtain full articles, \n",
    "## the ones that cannot be found in the corpus are disregarded.\n",
    "def getFields(article_texts, bsonFile):\n",
    "    # text, articleTitle, publishedDate, articleUrl \n",
    "    texts, titles, dates, url = [], [], [], []\n",
    "    \n",
    "    with open(bsonFile, 'rb') as f:\n",
    "        data = bson.decode_all(f.read())\n",
    "    \n",
    "    for sents in article_texts:\n",
    "        found = False\n",
    "        for item in data:\n",
    "            if all([sent in item['text'] for sent in sents]):\n",
    "                texts.append(item['text'])\n",
    "                titles.append(item['articleTitle'])\n",
    "                dates.append(item['publishedDate'])\n",
    "                url.append(item['articleUrl'])\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            texts.append('')\n",
    "            titles.append('')\n",
    "            dates.append(np.nan)\n",
    "            url.append('')\n",
    "\n",
    "    return texts, titles, url, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(df):\n",
    "    df = df.drop(columns=['Texts'])\n",
    "    df = df[df.Label != 0]\n",
    "    df = df[df.text != '']\n",
    "    return df\n",
    "\n",
    "## Articles collected, and mapped to a simulated timeline\n",
    "def joinDfs(df1, df2):\n",
    "    df = pd.concat([df1, df2])\n",
    "    df['Label'] = df['Label'].replace([-1], 0)\n",
    "    df = df.rename(columns={'date':'actualDate'})\n",
    "    \n",
    "    #Shuffle\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    #Change dates, divide it over 90 total days\n",
    "    imagDates, total = [], len(df)\n",
    "    eachCount = total/90\n",
    "    startDate = datetime.date(2011, 7, 1)\n",
    "    for i in range(total):\n",
    "         imagDates.append(startDate + timedelta(i/eachCount) )\n",
    "    df['date'] = imagDates\n",
    "    \n",
    "    #Transform data Strutcure to the correct format\n",
    "    df.insert(0, 'id', df.index)\n",
    "    df['Label'] = df['Label'].astype(int)\n",
    "    df['Label'] = [[x] for x in df['Label']]\n",
    "    df = df[['id', 'Label', 'text', 'date', 'title', 'url', 'actualDate']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "demon = getLabeledData(\"demon-predictions.csv\", 'demon.pkl')\n",
    "aadhar = getLabeledData(\"aadhar-predictions.csv\", 'aadhar.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "demon['text'], demon['title'], demon['url'], demon['date'] = \\\n",
    "    getFields(demon['Texts'], '../Base Implementation/data/demonetization-all.bson')\n",
    "aadhar['text'], aadhar['title'], aadhar['url'], aadhar['date'] = \\\n",
    "    getFields(aadhar['Texts'], '../Base Implementation/data/aadhar-all.bson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonCl = cleanUp(demon)\n",
    "aadharCl = cleanUp(aadhar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>actualDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Union Minister for Electronics &amp; Information T...</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>100 government websites to be differently-able...</td>\n",
       "      <td>http://indianexpress.com/article/india/india-n...</td>\n",
       "      <td>2016-08-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>By giving them all the pro-poor subsidies and ...</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>Rs 36,000 crore saved in one year through Jan ...</td>\n",
       "      <td>http://indianexpress.com/article/india/india-n...</td>\n",
       "      <td>2016-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>'UID data collection accurate'New Delhi, Jan 2...</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>'UID data collection accurate'</td>\n",
       "      <td>http://www.deccanherald.com/content/221680/uid...</td>\n",
       "      <td>2012-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Punjab Congress chief Captain Amarinder Singh ...</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>PM Modi Not Serious about Farmers' Woes: Capta...</td>\n",
       "      <td>http://www.hindustantimes.com/punjab/pm-modi-n...</td>\n",
       "      <td>2017-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>NEW DELHI: Four days before Prime Minister Nar...</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>Aadhaar gets a lifeline as Nandan Nilekani imp...</td>\n",
       "      <td>http://timesofindia.indiatimes.com//india/Aadh...</td>\n",
       "      <td>2014-11-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Label                                               text        date  \\\n",
       "0   0   [1]  Union Minister for Electronics & Information T...  2011-07-01   \n",
       "1   1   [0]  By giving them all the pro-poor subsidies and ...  2011-07-01   \n",
       "2   2   [1]  'UID data collection accurate'New Delhi, Jan 2...  2011-07-01   \n",
       "3   3   [0]  Punjab Congress chief Captain Amarinder Singh ...  2011-07-01   \n",
       "4   4   [1]  NEW DELHI: Four days before Prime Minister Nar...  2011-07-01   \n",
       "\n",
       "                                               title  \\\n",
       "0  100 government websites to be differently-able...   \n",
       "1  Rs 36,000 crore saved in one year through Jan ...   \n",
       "2                     'UID data collection accurate'   \n",
       "3  PM Modi Not Serious about Farmers' Woes: Capta...   \n",
       "4  Aadhaar gets a lifeline as Nandan Nilekani imp...   \n",
       "\n",
       "                                                 url  actualDate  \n",
       "0  http://indianexpress.com/article/india/india-n...  2016-08-24  \n",
       "1  http://indianexpress.com/article/india/india-n...  2016-11-14  \n",
       "2  http://www.deccanherald.com/content/221680/uid...  2012-01-23  \n",
       "3  http://www.hindustantimes.com/punjab/pm-modi-n...  2017-01-02  \n",
       "4  http://timesofindia.indiatimes.com//india/Aadh...  2014-11-21  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = joinDfs(demonCl, aadharCl)\n",
    "# id, Label, text, date, title, url, actualDate\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joined.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(data, open(\"data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('base': conda)",
   "language": "python",
   "name": "python36964bitbaseconda49a9dd99d5474024afc3b772952e9a45"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
